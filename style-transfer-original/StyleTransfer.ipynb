{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer\n",
    "Now, we should have all of the tool and concepts we need to implement style transfer!\n",
    "\n",
    "## Brief Overview\n",
    "\n",
    "1. Pick a content image and a style image\n",
    "2. Intialize the pastiche (the resulting image with the content of the content image and the style of the style image) - in this case, we will initialize the patiche to begin as the content image\n",
    "3. Run the content and style image through a pretrained VGG model\n",
    "    - For the content image, extract the convolutional features from ONE layer\n",
    "    - For the style image, extract the convolutional features from several layers - this will help with encapsulating global and local features of the style image\n",
    "4. For each iteration of gradient descent\n",
    "    - Run the pastiche through the VGG model and extract features from specified layers\n",
    "    - Construct the loss, total loss = content loss + style loss\n",
    "    - Update the pastiche to minimize loss\n",
    "    - Repeat\n",
    "\n",
    "Everything you will need is in this directory, as well as the methods you will complete. You can test your classes and functions by executing `python style_transfer_test.py <class/function name>`, i.e `python style_transfer_test.py load_images` or `python style_transfer_test.py ContentLoss`. You can test all by executing `python style_transfer_test.py all`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One: Initial Steps\n",
    "\n",
    "Implement `style_transfer.load_images`\n",
    "\n",
    "Implement `style_transfer.generate_pastiche`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: Content Loss\n",
    "In this part, we will focus on implementing the `ContentLoss` class in `style_transfer.py`.\n",
    "\n",
    "Remember that our loss can be split into a content loss and a style loss, both of which we want to minimize. To compare the content of the pastiche and the content image, we find the mean squared error between their corresponding feature matrices from layer 'r42' of the VGG Net. Let $P^\\ell$ be the feature matrix of the pastiche, and $C^\\ell$ be the feature matrix of the content image. Then we can calculate the content loss as we normally do when comparing tensors by using MSE.\n",
    "$$\\mathcal{L}_{content} = w_C\\frac{1}{n}\\sum_{w,c,h} (P^\\ell_{wch} - C^\\ell_{wch})^2$$\n",
    "Where the sum is just indexing into each element of the tensors, and $n$ is the total number of elements in the tensors. $w_C$ is a weight that we will put on the content loss so that the content/style losses will balance (and one will not but much bigger in magnitude than the other).\n",
    "\n",
    "It may help to use `nn.MSELoss` when implementing `ContentLoss`. In addition, take a look at `vgg.py` and see how to extract the specific feature layers of the cnn given the layer name (look at the `forward` method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three: Gram Matrix + Style Loss\n",
    "\n",
    "Implement `style_transfer.GramMatrix`. This implementation will be slightly different than your implementation in the GramMatrix Notebook. You will want to divide your final gram matrices by W*H (see docstring for details).\n",
    "\n",
    "Implement `StyleLoss`. It is very similar to content loss, but instead of the MSE between the feature matrices, it is the MSE between the corresponding Gram Matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Four: Constructing the Loss Function\n",
    "\n",
    "Implement `construct_style_loss_fns` and `construct_content_loss_fns`. In order to implement this functions, you will need to construct a list of StyleLoss or ContentLoss (depending on the function) for each specified layer. In addition, you will need to know how much each loss will be weighted. The content layer loss weight is just $1.0$. For each style layer, the loss weight is $w = \\frac{1000}{n^2}$, where $n$ is the number of output filters of the corresponding most recent convolutional layer. In order to figure out the number of output filters of the convolutional net layer, look at the model architecture in `vgg.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Four: Putting it all Together\n",
    "\n",
    "Fill out `main()`. You should be using all of the functions you have written before. If you get stuck at what to do, follow the steps in the brief overview above When you think that you've implemented it correctly, you can run the script in your terminal by typing `python style_transfer.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my output and loss values (you should be getting values similar to this, or lower), as well as my corresponding output image.\n",
    "<img src=\"Images/style_transfer_loss.png\">\n",
    "<img src=\"Images/style_transfer_output.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ulab]",
   "language": "python",
   "name": "conda-env-ulab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
