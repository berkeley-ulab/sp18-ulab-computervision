{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also known as *Deep Learning*...\n",
    "\n",
    "Deep learning/neural networks is a machine learning algorithm that teaches computers to do what comes naturally to humans: learn by example. \n",
    "\n",
    "In deep learning, a computer model learns to perform classification tasks directly from images, text, or sound. Deep learning models can achieve state-of-the-art accuracy, sometimes exceeding human-level performance. Models are trained by using a large set of labeled data and neural network architectures that contain many layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area of Neural Networks has originally been primarily inspired by the goal of modeling biological neural systems, but has since diverged and become a matter of engineering and achieving good results in Machine Learning tasks. \n",
    "\n",
    "Nonetheless, we begin our discussion with a very brief and high-level description of the biological system that a large portion of this area has been inspired by.\n",
    "\n",
    "Credit to http://cs231n.github.io/neural-networks-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological \"Inspiration\"\n",
    "\n",
    "Remember, this is \"inspiration\". Don't go around saying that we're making human brains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing inspiration from the basic unit of the brain, the neuron:\n",
    "\n",
    "<img src=\"tutorial_img/neurons.png\" width=\"423\">\n",
    "\n",
    "Approximately 86 billion neurons can be found in the human nervous system and they are connected with approximately $10^{14}$ to $10^{15}$ **synapses**. \n",
    "Each neuron receives input signals from its **dendrites** and produces output signals along its (single) **axon**. The **axon** eventually branches out and connects via synapses to dendrites of other neurons. A **synapse** is a structure that permits a neuron (or nerve cell) to pass an electrical or chemical signal to another neuron or to the target efferent cell. (See Wikipedia).\n",
    "\n",
    "The idea is that the synaptic strengths are learnable and control the strength of influence (and its direction: excitory (positive) or inhibitory (negative)) of one neuron on another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the Neuron\n",
    "We can try to model this as the following.\n",
    "\n",
    "<img src=\"tutorial_img/neuron_model.jpg\" width=\"423\">\n",
    "\n",
    "In the computational model of a neuron, the signals that travel along the **axons** interact multiplicatively (e.g. $w_0x_0$) with the dendrites of the other neuron based on the synaptic strength at that synapse (e.g. $w_0$). In the basic model, the dendrites carry the signal to the cell body where they all get summed. If the final sum is above a certain threshold, the neuron can fire, sending a spike along its axon.\n",
    "\n",
    "A common way of modeling this threshold is by using the **sigmoid function** as an activation: $\\sigma(x) = 1 / (1 + e^{-x})$. As shown below, where the x axis is your input:\n",
    "\n",
    "<img src=\"tutorial_img/activations/sigmoid.jpg\" width=\"423\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... b?\n",
    "\n",
    "Did you notice this? This was in the above computational model of the neuron. We call this the *bias term*. This is used for learning purposes - a bias value allows you to shift the activation function to the left or right, which may be critical for successful learning. One interpretation is that it lowers the threshold for activation for a given input.\n",
    "\n",
    "\n",
    "<img src=\"tutorial_img/activations/bias.png\" width=\"423\">\n",
    "\n",
    "https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your understanding:\n",
    "\n",
    "Fill out the following class to model a neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "class Neuron(object):\n",
    "    def __init__(self, input_size: int):\n",
    "        # Don't modify!\n",
    "        self.w = np.random.rand(input_size)\n",
    "        self.bias = np.random.rand()\n",
    "    \n",
    "    def forward(self, inputs: np.ndarray):\n",
    "        \"\"\"Assume inputs and weights are 1-D numpy arrays and bias is a number.\n",
    "        \n",
    "        Use the sigmoid function as your activation function.\n",
    "\n",
    "        Example:\n",
    "             >>> neuron = Neuron(2)\n",
    "             >>> x = neuron.forward(np.array([0, 1]))\"\"\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test if your code worked\n",
    "def testNeuron():\n",
    "    np.random.seed(1)\n",
    "    n = Neuron(10)\n",
    "    result = n.forward(np.ones(10))\n",
    "    if abs(result - 0.972494) < 0.00001:\n",
    "        print(\"Pass!\")\n",
    "    else:\n",
    "        print(\"Incorrect implementation of neuron... - got %f\" % result)\n",
    "    \n",
    "testNeuron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So now we have a neuron, what next? \n",
    "\n",
    "Well, we make more neurons, and we connect them together...\n",
    "\n",
    "<img src=\"tutorial_img/few_neuron.png\" width=\"423\">\n",
    "\n",
    "As you can see, there are 4 neurons in this above picture. Then, we can keep doing this ...\n",
    "\n",
    "<img src=\"tutorial_img/neural_net.jpg\" width=\"423\">\n",
    "\n",
    "How many parameters are there in this neural network? A weight value or a bias values counts as *1* parameter.\n",
    "\n",
    "*Note that each neuron at each layer is connected to all neurons at the next layer. This is called a **fully connected layer**.*\n",
    "\n",
    "Try building your own, with the below class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Neuron class here, or else your tests will fail\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_size: int):\n",
    "        #  maintain this ordering please\n",
    "        self.layer_1 = None  # implement\n",
    "        self.layer_2 = None\n",
    "        self.layer_output = Neuron(4)\n",
    "    \n",
    "    def forward(self, inputs: np.ndarray):\n",
    "        raise NotImplementedError  # implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "def testNeuralNetwork(seed, size):\n",
    "    np.random.seed(seed)\n",
    "    n = NeuralNetwork(size)\n",
    "    return n.forward(np.ones(size)) \n",
    "\n",
    "assert abs(testNeuralNetwork(seed=1, size=5) - 0.87080997) < 0.00001, \"Test failed...\"\n",
    "assert abs(testNeuralNetwork(seed=2, size=20) - 0.9478807) < 0.00001, \"Test failed...\"\n",
    "assert abs(testNeuralNetwork(seed=5, size=100) - 0.912289) < 0.00001, \"Test failed...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to implement the same thing using numpy and not using the Neuron class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpNeuralNetwork(object):\n",
    "    def __init__(self, input_size: int):\n",
    "        self.layer_1 = np.random.rand(input_size,4)\n",
    "        self.layer_1_b = np.random.rand(4)\n",
    "        self.layer_2 = np.random.rand(4,4)\n",
    "        self.layer_2_b = np.random.rand(4)\n",
    "        self.layer_output =  np.random.rand(4, 1)\n",
    "        self.layer_output_b = np.random.rand()\n",
    "    \n",
    "    def forward(self, inputs: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def testNpNeuralNetwork(seed, size):\n",
    "    np.random.seed(seed)\n",
    "    n = NpNeuralNetwork(size)\n",
    "    return n.forward(np.ones(size)) \n",
    "\n",
    "assert (testNpNeuralNetwork(seed=1, size=5) - 0.85539851) < 0.00001, \"Test failed...\"\n",
    "assert (testNpNeuralNetwork(seed=2, size=20) - 0.95576044) < 0.00001, \"Test failed...\"\n",
    "assert (testNpNeuralNetwork(seed=5, size=100) - 0.92951435) < 0.00001, \"Test failed...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optionally) Do all of this in Torch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we make these things learn? See the Gradient Descent notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
